{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9490d7-ec97-4a1d-a71e-5ffbf9764957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully installed langchain-0.3.23 langchain-core-0.3.74 langchain-text-splitters-0.3.9 langsmith-0.3.45 orjson-3.11.2 requests-toolbelt-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed cachetools-6.1.0 ibm-cos-sdk-2.14.3 ibm-cos-sdk-core-2.14.3 ibm-cos-sdk-s3transfer-2.14.3 ibm-watsonx-ai-1.3.34 jmespath-1.0.1 langchain-ibm-0.3.10 lomond-0.3.3 numpy-2.3.2 pandas-2.2.3 requests-2.32.5 tabulate-0.9.0 tzdata-2025.2 urllib3-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed dataclasses-json-0.6.7 httpx-sse-0.4.1 langchain-community-0.3.16 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed wikipedia-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed jiter-0.10.0 openai-1.77.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed langchain-openai-0.3.16 regex-2025.7.34 tiktoken-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Successfully installed langgraph-0.6.1 langgraph-checkpoint-2.1.1 langgraph-prebuilt-0.6.4 langgraph-sdk-0.2.3 ormsgpack-1.10.0 xxhash-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain==0.3.23 | tail -n 1 \n",
    "%pip install langchain-ibm==0.3.10 | tail -n 1 \n",
    "%pip install langchain-community==0.3.16 | tail -n 1 \n",
    "%pip install wikipedia==1.4.0 | tail -n 1\n",
    "%pip install openai==1.77.0 | tail -n 1\n",
    "%pip install langchain-openai==0.3.16 | tail -n 1\n",
    "%pip install langgraph==0.6.1 | tail -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "384fd03f-abd3-4682-8bba-5e0b17a80205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ibm import ChatWatsonx\n",
    "from langchain.agents import AgentType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37d7e63-4796-4acb-a9a1-c97808f2cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatWatsonx(\n",
    "    model_id=\"ibm/granite-3-2-8b-instruct\",\n",
    "    url=\"https://us-south.ml.cloud.ibm.com\",\n",
    "    project_id=\"skills-network\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a2e0d495-3ee8-4d49-b639-a9eda2a67fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Response Content:  Both LangChain and LangGraph are interesting projects in the AI domain, but neither is typically used as a primary framework for building AI agents. \n",
      "\n",
      "1. LangChain: This is a decentralized application (dApp) platform that enables the creation of language-based apps, not specifically an AI agent framework. It's designed for building decentralized applications that incorporate language models and blockchain technologies, focusing more on the infrastructure and interaction rather than the core AI agent development.\n",
      "\n",
      "2. LangGraph: LangGraph is a knowledge graph construction system from semantic web data sources that uses language models to accelerate the process. It serves as a tool to automatically build a knowledge graph from unstructured data, utilizing natural language processing, but again, it's not a framework for building AI agents per se.\n",
      "\n",
      "For building AI agents, you might want to consider more established frameworks such as:\n",
      "\n",
      "1. TensorFlow or PyTorch: These are powerful, open-source libraries used for machine learning and artificial intelligence. They are versatile and provide the foundation for a range of AI applications, including building AI agents.\n",
      "\n",
      "2. RLlib or Stable Baselines3: If you're interested in reinforcement learning, which is a key method for creating AI agents, these libraries offer tools and pre-implemented RL algorithms.\n",
      "\n",
      "3. Rasa: It is an open-source machine learning framework specifically designed for building AI agents or chatbots, focusing more on dialogue management.\n",
      "\n",
      "4. Deep Learning Frameworks like Gensim, SpaCy for NLP tasks, or Even Older but still powerful tools like WEKA or MOA for traditional machine learning tasks.\n",
      "\n",
      "In conclusion, none of LangChain or LangGraph are standalone frameworks for building AI agents. They each offer unique services within the AI ecosystem, but for constructing AI agents, you would likely need to combine them with more specialized tools like TensorFlow, PyTorch, RLlib, Rasa, etc.\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke(\"What framework do you recommend for building AI Agents - LangChain or LangGraph?\")\n",
    "print(\"\\nResponse Content: \", response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9548649-7ce8-4772-8347-e19b65b72e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19a1091b-5d1c-44b8-9170-2654dbcfe949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a39a202f-8c7b-46a6-ae9c-92b2e1204022",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def sum_numbers_from_text(inputs: str) -> float:\n",
    "    \"\"\"\n",
    "    Adds a list of numbers provided in the input string.\n",
    "    \n",
    "    Args:\n",
    "        text: A string containing numbers that should be extracted and summed.\n",
    "        \n",
    "    Returns:\n",
    "        The sum of all numbers found in the input.\n",
    "    \"\"\"\n",
    "    # Use regular expressions to extract all numbers from the input\n",
    "    numbers = [int(num) for num in re.findall(r'\\d+', inputs)]\n",
    "    result = sum(numbers)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95b1cf23-409b-425d-9bef-a80c0e482aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: \n",
      " sum_numbers_from_text\n",
      "Description: \n",
      " Adds a list of numbers provided in the input string.\n",
      "\n",
      "Args:\n",
      "    text: A string containing numbers that should be extracted and summed.\n",
      "\n",
      "Returns:\n",
      "    The sum of all numbers found in the input.\n",
      "Args: \n",
      " {'inputs': {'title': 'Inputs', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"Name: \\n\", sum_numbers_from_text.name)\n",
    "print(\"Description: \\n\", sum_numbers_from_text.description) \n",
    "print(\"Args: \\n\", sum_numbers_from_text.args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0803ef16-d49b-4470-a00c-00b8729c6dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_exec = create_react_agent(model=llm, tools=[sum_numbers_from_text])\n",
    "msgs = agent_exec.invoke({\"messages\": [(\"human\", \"Add the numbers -10, -20, -30\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c728d68f-1b7c-4610-89f2-d6a197e7b7e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the numbers -10, -20, and -30 is 60.\n"
     ]
    }
   ],
   "source": [
    "print(msgs[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f1b2a-136e-45ff-a710-1704cf944c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "# Create a Wikipedia tool using the @tool decorator\n",
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Search Wikipedia for factual information about a topic.\n",
    "    \n",
    "    Parameters:\n",
    "    - query (str): The topic or question to search for on Wikipedia\n",
    "    \n",
    "    Returns:\n",
    "    - str: A summary of relevant information from Wikipedia\n",
    "    \"\"\"\n",
    "    wiki = WikipediaAPIWrapper()\n",
    "    return wiki.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6709cb7b-1c73-4fd8-8b4b-2fc93124fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_wikipedia.invoke(\"What is tool calling?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cc10ef-bb8c-461d-a3f2-821edbc82a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update your tools list to include the Wikipedia tool\n",
    "tools_updated = [sum_numbers_from_text, search_wikipedia]\n",
    "\n",
    "# Create the agent with all tools including Wikipedia\n",
    "math_agent_updated = create_react_agent(\n",
    "    model=llm,\n",
    "    tools=tools_updated,\n",
    "    prompt=\"You are a helpful assistant that can perform various mathematical operations and look up information. Use the tools precisely and explain your reasoning clearly.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06458160-afc8-491e-b6b2-167f7ee46677",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the population of Canada? Add another million to it\"\n",
    "\n",
    "response = math_agent_updated.invoke({\"messages\": [(\"human\", query)]})\n",
    "\n",
    "print(\"\\nMessage sequence:\")\n",
    "for i, msg in enumerate(response[\"messages\"]):\n",
    "    print(f\"\\n--- Message {i+1} ---\")\n",
    "    print(f\"Type: {type(msg).__name__}\")\n",
    "    if hasattr(msg, 'content'):\n",
    "        print(f\"Content: {msg.content}\")\n",
    "    if hasattr(msg, 'name'):\n",
    "        print(f\"Name: {msg.name}\")\n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(f\"Tool calls: {msg.tool_calls}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
